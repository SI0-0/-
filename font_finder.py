import streamlit as st
from PIL import Image
import numpy as np
import cv2
from font_classify import FontClassifier  # GitHub íŒ¨í‚¤ì§€
import torch

st.set_page_config(
    page_title="AI í°íŠ¸ ì°¾ê¸°",
    page_icon="ğŸ”",
    layout="centered"
)

# ===============================
#   Custom UI ìŠ¤íƒ€ì¼
# ===============================
st.markdown("""
<style>
.title {
    font-size: 2.3rem;
    font-weight: 700;
    text-align: center;
    margin-bottom: 0.7rem;
}
.subtitle {
    text-align: center;
    font-size: 1.05rem;
    color: #666;
    margin-bottom: 2rem;
}
.font-card {
    padding: 1rem;
    border-radius: 14px;
    background: #fafafa;
    margin-bottom: 0.7rem;
    border: 1px solid #e3e3e3;
}
.font-name {
    font-size: 1.1rem;
    font-weight: 600;
}
</style>
""", unsafe_allow_html=True)


# ===============================
#   Header
# ===============================
st.markdown('<div class="title">ğŸ” AI í°íŠ¸ ì°¾ê¸°</div>', unsafe_allow_html=True)
st.markdown('<div class="subtitle">ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ì—ì„œ ê¸€ì ì˜ì—­ì„ ì¶”ì¶œí•˜ê³ ,<br>AIê°€ ë¹„ìŠ·í•œ í°íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤.</div>', unsafe_allow_html=True)


# ===============================
#   Font Classifier ë¡œë“œ
# ===============================
@st.cache_resource
def load_model():
    # pretrained=True â†’ GitHub ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ
    return FontClassifier(pretrained=True)

model = load_model()


# ===============================
#   ì´ë¯¸ì§€ ì—…ë¡œë“œ
# ===============================
uploaded_file = st.file_uploader("ğŸ“¤ í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”",
                                 type=["png", "jpg", "jpeg", "bmp"])

if uploaded_file is not None:
    image = Image.open(uploaded_file).convert("RGB")
    st.image(image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_column_width=True)

    img_np = np.array(image)

    # ===============================
    #   í…ìŠ¤íŠ¸ ì˜ì—­ ìë™ ì¶”ì¶œ(OpenCV)
    # ===============================
    def extract_text_region(img):
        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (22, 6))
        dilated = cv2.dilate(thresh, kernel, iterations=2)

        contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if not contours:
            return None

        biggest = max(contours, key=cv2.contourArea)
        x, y, w, h = cv2.boundingRect(biggest)
        return img[y:y+h, x:x+w]

    text_region = extract_text_region(img_np)

    if text_region is None:
        st.warning("âš ï¸ í…ìŠ¤íŠ¸ ì˜ì—­ì„ ìë™ìœ¼ë¡œ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” ì„ ëª…í•œ ì´ë¯¸ì§€ë¡œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
    else:
        st.image(text_region, caption="ê°ì§€ëœ í…ìŠ¤íŠ¸ ì˜ì—­", use_column_width=True)


    # ===============================
    #   ë²„íŠ¼ â†’ í°íŠ¸ ë¶„ì„ ì‹¤í–‰
    # ===============================
    if st.button("ğŸ” ë¹„ìŠ·í•œ í°íŠ¸ ì°¾ê¸°"):
        with st.spinner("AIê°€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤â€¦"):

            # PIL í˜•íƒœë¡œ ë³€í™˜
            text_region_pil = Image.fromarray(text_region)

            # font-classify ëª¨ë¸ í˜¸ì¶œ
            results = model.predict_topk(text_region_pil, k=8)
            # ê²°ê³¼ í˜•ì‹ ì˜ˆ: [("Roboto", 0.82), ("Noto Sans", 0.74), ...]

        st.success("ğŸ‰ ë¹„ìŠ·í•œ í°íŠ¸ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")

        # ===============================
        #   ê²°ê³¼ ì¶œë ¥
        # ===============================
        for font, score in results:
            st.markdown(f"""
                <div class="font-card">
                    <div class="font-name">{font}</div>
                    <div style="color:#888;">ìœ ì‚¬ë„: {score*100:.1f}%</div>
                </div>
            """, unsafe_allow_html=True)
